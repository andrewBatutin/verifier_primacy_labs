---
title: "VERIFIER PRIMACY"
subtitle: "Building Trust in AI Systems"
author: "Andriy Batutin"
date: "03.02.2026"
format:
  revealjs:
    theme: [dark, custom.scss]
    slide-number: true
    preview-links: auto
    transition: slide
    background-transition: fade
    highlight-style: github-dark
    code-line-numbers: false
    footer: "Verifier Primacy | [andriybatutin.substack.com](https://andriybatutin.substack.com/)"
    width: 1920
    height: 1080
    margin: 0.1
    center: true
    hash: true
    history: true
    controls: true
    progress: true
    touch: true
execute:
  echo: false
  warning: false
---

# {background-color="#0F172A"}

::: {.r-fit-text}
**VERIFIER PRIMACY**
:::

Building Trust in AI Systems

::: {.fragment .fade-up}
*Andriy Batutin • SKELAR Analytics MeetUP • Warsaw 2026*
:::

---

## {background-color="#0F172A"}

::: {.r-fit-text style="color: #DC2626;"}
In the next 12 months,
:::

::: {.fragment .fade-up}
a C-level executive will lose their job
:::

::: {.fragment .fade-up}
because of a critical AI failure.
:::

::: {.fragment .fade-up style="color: #0891B2; font-style: italic;"}
[OpenRouter data](https://openrouter.ai/state-of-ai) supports this.
:::

::: {.notes}
This isn't fear-mongering. This is what the data shows.

OpenRouter's State of AI report: reasoning tokens went from 0% to 50%+ in 12 months.
Prompt complexity quadrupled. Organizations are deploying agents at scale.

But verification infrastructure hasn't kept pace. That gap is the risk.
:::

---

## {background-color="#0F172A"}

![](images/reasoning-tokens-growth.png){fig-align="center" width="80%"}

::: {.aside}
Source: [OpenRouter State of AI 2025](https://openrouter.ai/state-of-ai)
:::

---

## The Governance Gap {background-color="#0F172A"}

::: {.columns}
::: {.column width="50%"}
### [KPMG 2025](https://kpmg.com/xx/en/our-insights/ai-and-technology/trust-attitudes-and-use-of-ai.html)
*48,000 people, 47 countries*

- **56%** making mistakes due to AI
- **66%** don't verify AI outputs
- **46%** trust AI systems

:::

::: {.column width="50%"}
### [Deloitte 2026](https://www.deloitte.com/us/en/about/press-room/state-of-ai-report-2026.html)
*3,235 leaders, 24 countries*

- **75%** deploying agentic AI
- **21%** have governance models
- **25%** moving pilots to production

:::
:::

::: {.fragment .fade-up style="background-color: #DC2626; padding: 20px; border-radius: 8px; margin-top: 30px; text-align: center;"}
**The gap between deployment and governance is the liability.**
:::

---

## Today's Journey

::: {.incremental}
1. **The Stochasticity Paradox** — Why AI is chaos by design
2. **From Retrieval to Action** — The escalating risk ladder
3. **Agentic Case Study** — When the agent acts on bad info
4. **The Verification Stack** — Mathematical foundations
5. **Verifier Primacy** — Scaling judgment as infrastructure
:::

::: {.notes}
The arc: WHY → WHAT GOES WRONG → HOW TO FIX IT

Focus on agentic because that's where the real liability concentrates.
RAG gives wrong answers. Agents take wrong actions.
:::

---

# The Stochasticity Paradox {background-color="#1E293B"}

*Why AI cannot be made reliable — and why that's the point*

---

## The Problem

::: {.columns}
::: {.column width="50%" style="background-color: #7F1D1D; padding: 20px; border-radius: 8px;"}
### The Fear

- AI outputs are unpredictable
- Wrong action = lawsuit
- Career ends in headline

:::

::: {.column width="50%" style="background-color: #1E3A5F; padding: 20px; border-radius: 8px;"}
### The FOMO

- Competitors are shipping AI
- Boards expect transformation
- "Laggard" is career poison

:::
:::

::: {.fragment .fade-up style="margin-top: 40px; text-align: center;"}
**Both paths feel like career risk.**
:::

::: {.fragment .fade-up style="background-color: #7C3AED; padding: 20px; border-radius: 8px; margin-top: 20px; text-align: center;"}
And here's the uncomfortable truth:

**The unpredictability you fear is exactly what makes AI useful.**

A perfectly reliable AI is a database.
:::

---

# Fundamentals of Modern AI Stack {background-color="#1E293B"}

---

## The Autoregressive Decoder

::: {.callout-note appearance="minimal"}
## LLMs Are Conditional Probability Machines
:::

$$P(x_1, x_2, \ldots, x_T) = \prod_{t=1}^{T} P(x_t \mid x_{<t})$$

Each token is a **local decision** based on preceding context.

::: {.fragment .fade-up style="background-color: #DC2626; padding: 20px; border-radius: 8px; margin-top: 20px;"}
**The Butterfly Effect**: One different token → completely different output.

Errors compound multiplicatively: $\prod_{t=1}^{T} \epsilon_t$
:::

---

## {background-color="#0F172A"}

![](images/llm_slot_machine.png){fig-align="center" width="70%"}

::: {.fragment .fade-up style="margin-top: 30px; text-align: center; font-size: 1.3em;"}
Every token is a spin. The house always has edge.
:::

---

## Information Imbalance

::: {.callout-warning appearance="minimal"}
## Query Entropy << Document Entropy
:::

$$H(\text{Query}) \ll H(\text{Document})$$

::: {.columns}
::: {.column width="50%"}
### The Question

"Is knee surgery covered?"

**= 4 tokens**

:::

::: {.column width="50%"}
### The Answer Location

Page 147, Section 8.3.2(b)

Endorsement CP-1147, Exclusion (iii)

:::
:::

::: {.fragment .fade-up style="background-color: #7C3AED; padding: 20px; border-radius: 8px; margin-top: 30px; text-align: center;"}
**You're asking search to read minds.**
:::

---

## The Retrieval Problem

::: {.columns}
::: {.column width="50%" style="background-color: #1E3A5F; padding: 20px; border-radius: 8px;"}
### Semantic Search Fails

In high-dimensional space:

$$\cos(a, b) \approx \cos(a, c) \quad \forall a, b, c$$

**Similar ≠ Relevant**

"What's my deductible?" ≈ "What is a deductible?"

:::

::: {.column width="50%" style="background-color: #7F1D1D; padding: 20px; border-radius: 8px;"}
### Keyword Search Fails

Synonymy & polysemy break everything:

- "coverage" ≠ "benefits"
- "benefits" ≠ "included services"
- "included services" ≠ "covered procedures"

**Same concept, different words.**

:::
:::

::: {.fragment .fade-up style="background-color: #0F172A; padding: 20px; border-radius: 8px; margin-top: 30px; text-align: center;"}
**RAG retrieves plausible documents. LLM generates confident answers.**

But confidence ≠ correctness.
:::

---

## Agentic Combinatorial Explosion

::: {.callout-important appearance="minimal"}
## The Action Space Is Intractable
:::

$$|\text{Action Space}| = n_{\text{tools}} \times m_{\text{params}} \times k_{\text{steps}}$$

::: {.fragment}
8 tools × 5 params × 4 steps = **12,800+ trajectories**

Per claim. 500 claims/day.
:::

::: {.fragment style="background-color: #0F172A; padding: 20px; border-radius: 8px; margin-top: 30px; text-align: center;"}
**No exhaustive testing possible.**

You're sampling from chaos.
:::

---

## {background-color="#0F172A"}

![](images/ai_casino.png){fig-align="center" width="80%"}

::: {.fragment .fade-up style="background-color: #DC2626; padding: 20px; border-radius: 8px; margin-top: 30px; text-align: center; font-size: 1.3em;"}
**Every query is a pull. Every action is a bet.**

You expected to win? The math says no.
:::

---

## {background-color="#7C3AED"}

::: {.r-fit-text}
Leaders must approach building AI systems

with the mentality of a **casino owner**,

not a casino player.
:::

::: {.fragment .fade-up style="margin-top: 40px; font-size: 1.5em;"}
**That is how they will win in the long run.**
:::

---

# Real World Insurance Org Structure {background-color="#1E293B"}

*How AI Can Actuate Risks Instead of Decreasing Them*

---

## {background-color="#0F172A"}

![](images/insurance_org.png){fig-align="center" width="85%"}

---

## {background-color="#0F172A"}

![](images/Insurance_risk_ladder.png){fig-align="center" width="85%"}

---

# Risk Decomposition {background-color="#1E293B"}

---

## RAG: The Foundation Problem

::: {.columns}
::: {.column width="50%" style="background-color: #1E3A5F; padding: 20px; border-radius: 8px;"}
### What RAG Promises

- "Ground AI in your documents"
- "Reduce hallucinations"
- "Enterprise-ready AI"

:::

::: {.column width="50%" style="background-color: #7F1D1D; padding: 20px; border-radius: 8px;"}
### What RAG Delivers

- Retrieves **plausible** docs
- Misses **critical** exclusions
- Confident answers from **wrong** context

:::
:::

::: {.fragment style="background-color: #0F172A; padding: 20px; border-radius: 8px; margin-top: 30px; text-align: center;"}
**You already saw the math: Info gap + Retrieval failure + Compounding errors.**

RAG inherits all the problems. It doesn't solve them.
:::

---

## RAG Failure: Annoying but Recoverable

**Customer**: "Is my knee surgery covered?"

**AI**: "Yes, orthopedic procedures are covered." *(wrong — exclusion on page 147)*

::: {.columns}
::: {.column width="50%"}
### What Happens

- Customer calls to confirm
- Agent catches the error
- Correct info provided
- Minor embarrassment

:::

::: {.column width="50%"}
### The Saving Grace

**Human in the loop.**

Customer still has to act.

Time to catch mistakes.

:::
:::

::: {.fragment style="background-color: #1E3A5F; padding: 20px; border-radius: 8px; margin-top: 20px; text-align: center;"}
**RAG is passive. Wrong info waits for someone to act on it.**
:::

---

## Agentic AI: No Safety Net

**Same RAG retrieval. But now the agent ACTS.**

::: {.columns}
::: {.column width="50%"}
### What Changes

- Agent has tools: `approve_claim`, `send_payment`, `update_record`
- Same wrong retrieval
- Same confident LLM
- **But now it executes**

:::

::: {.column width="50%"}
### The Consequence

No human checkpoint.

Action happens at machine speed.

By the time you notice, **damage is done**.

:::
:::

::: {.fragment style="background-color: #DC2626; padding: 20px; border-radius: 8px; margin-top: 20px; text-align: center;"}
**Agentic AI multiplies RAG failures by the cost of autonomous action.**
:::

---

# The Rubber Stamp Trap {background-color="#1E293B"}

*When "Human in the Loop" Becomes Human-Shaped Decoration*

---

## The Setup: Kraków Back Office

::: {.columns}
::: {.column width="48%" style="background-color: #1E3A5F; padding: 25px; border-radius: 8px;"}
### Claims Department

- **Staff:** 12 adjusters
- **Volume:** 500+ claims/day
- **Target:** 45 claims/adjuster/day
- **Avg time:** 10-12 minutes per claim
:::

::: {.column width="48%" style="background-color: #065F46; padding: 25px; border-radius: 8px;"}
### NEW: AI Claims Assistant

- Reads claim documents
- Pulls policy from admin system
- Checks coverage rules
- Calculates recommended payout
- Presents recommendation to adjuster
:::
:::

::: {.fragment style="background-color: #7F1D1D; padding: 20px; border-radius: 8px; margin-top: 30px; text-align: center;"}
**AI DOES NOT have authority to approve. AI DOES NOT have access to payment system.**

Human adjuster must click [APPROVE] or [REJECT]. *"Human in the loop. Completely safe."*
:::

---

## Maria's Screen — 09:47 AM

```
┌─────────────────────────────────────────────────────────────────────────┐
│  CLAIMS WORKBENCH                                       Maria Kowalska  │
│  Queue: 47 claims remaining              Today: 18/45 processed         │
├─────────────────────────────────────────────────────────────────────────┤
│  CLAIM #WD-2847 | Water Damage - Commercial Property                    │
│  Claimant: Restauracja Złota Kaczka Sp. z o.o. | Policy: CP-847291      │
│                                                                         │
│  ┌───────────────────────────────────────────────────────────────────┐  │
│  │   ███  AI ASSISTANT RECOMMENDATION  ███                           │  │
│  │   Coverage: ✓ APPLIES          Policy Status: ✓ ACTIVE            │  │
│  │   Deductible: PLN 5,000        Coverage Limit: PLN 500,000        │  │
│  │   Damage Assessment: PLN 43,500                                   │  │
│  │   Less Deductible:   PLN  5,000                                   │  │
│  │   ─────────────────────────────                                   │  │
│  │   RECOMMENDED PAYOUT: PLN 38,500    Confidence: 94%               │  │
│  └───────────────────────────────────────────────────────────────────┘  │
│       [ APPROVE ]         [ REJECT ]         [ ESCALATE ]               │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## What Maria Does

::: {.columns}
::: {.column width="50%"}
**09:47:12 — Maria sees:**

- Water damage ✓ *(common claim type)*
- Commercial property ✓ *(handles daily)*
- Coverage applies ✓ *(AI checked)*
- Amount reasonable ✓ *(within limits)*
- Confidence 94% ✓ *(AI is sure)*
- 47 claims still in queue ✗ *(pressure)*
:::

::: {.column width="50%"}
**Maria thinks:**

*"AI already checked the policy. 94% confidence. Amount under PLN 50k so no escalation needed. Looks standard."*

**09:47:38** — Maria clicks: **[APPROVE]**

::: {.fragment style="background-color: #DC2626; padding: 15px; border-radius: 8px; margin-top: 20px; text-align: center;"}
**Time spent on claim: 26 seconds**
:::
:::
:::

---

## What Maria Should Have Checked

::: {.columns}
::: {.column width="50%"}
**IF [View Policy] — Page 147:**

```
ENDORSEMENT CP-1147 - WATER DAMAGE

Coverage for water damage LIMITED TO
sudden and accidental discharge.

EXCLUDED:
- Gradual seepage >14 days
- Damage from lack of maintenance
- Known source not repaired
```
:::

::: {.column width="50%"}
**IF [View Claim Form]:**

```
Section 3: Description of Loss

"We noticed water stains on ceiling
in November. Thought it was
condensation. On January 15 ceiling
collapsed. Plumber found pipe had
been leaking for 'at least 2-3
months' based on corrosion."
```
:::
:::

::: {.fragment style="background-color: #DC2626; padding: 20px; border-radius: 8px; margin-top: 20px; text-align: center;"}
**GRADUAL LEAK = EXCLUDED | CORRECT PAYOUT = PLN 0**
:::

---

## What the AI Missed (and Why)

::: {.columns}
::: {.column width="50%"}
### AI Retrieval

✓ Found policy CP-847291
✓ Found base coverage
✓ Found deductible: PLN 5,000
✗ **Did NOT retrieve Endorsement CP-1147**

*Why? Endorsement in separate DMS. RAG query "water damage coverage" returned base policy. "CP-1147" doesn't contain "water".*
:::

::: {.column width="50%"}
### AI Reasoning

✓ Water damage covered *(generally true)*
✓ Policy is active
✓ Amount within limits
✗ **Did NOT parse "2-3 months"**
✗ **Did NOT flag gradual vs sudden**

*Why? Scanned PDF, OCR 87%. Free text. No structured field. Janet knows this. AI doesn't.*
:::
:::

---

## The Aftermath

```
09:47:38    Maria clicks [APPROVE]
09:47:39    System logs: "Claim WD-2847 APPROVED by Maria Kowalska"
09:48:00    Maria is already on Claim #WD-2848

Day +3      Payment of PLN 38,500 processed
Day +47     Monthly audit sample pulls Claim WD-2847
Day +48     Senior Adjuster: "Why did we pay this? It's gradual damage."
Day +49     Recovery attempted. Claimant: "We have approval confirmation."
Day +51     Legal involved. Claimant has written record.

Day +180    Pattern discovered. 23 similar claims. Total: PLN 847,000
```

---

## The Accountability Question

::: {.columns}
::: {.column width="50%"}
**MARIA:** *"AI said it was covered. 94% confidence. I can't check every endorsement on every claim. I process 45/day."*

**IT:** *"AI performed as designed. Human approval is required precisely for edge cases. The human approved it."*
:::

::: {.column width="50%"}
**CLAIMS MGR:** *"We set 45/day target based on AI assistance. That's what we promised the board."*

**VP:** *"The audit trail shows human approval. That's our compliance defense. ...right?"*
:::
:::

::: {.fragment style="background-color: #7C3AED; padding: 20px; border-radius: 8px; margin-top: 30px; text-align: center;"}
**"Human in the loop" became "Human as rubber stamp"**

The human isn't REVIEWING. The human is LEGITIMIZING.
:::

---

## The Math of Rubber Stamping

::: {.columns}
::: {.column width="50%"}
### Before AI

- Claims/day/adjuster: **15**
- Time per claim: **30 min**
- Error rate: **2%**
- Human catches own mistakes: **80%**
- **Net errors/day: 0.06**
:::

::: {.column width="50%"}
### After AI (Rubber Stamping)

- Claims/day/adjuster: **45**
- Time per claim: **10 min** *(mostly AI)*
- AI error rate: **5%**
- Human override rate: **3%**
- **Net errors/day: ~2.0**
:::
:::

::: {.fragment style="background-color: #DC2626; padding: 20px; border-radius: 8px; margin-top: 20px; text-align: center;"}
12 adjusters × 2 errors/day × 220 days = **5,280 errors/year**

Avg overpayment: PLN 35,000 → **Annual exposure: PLN 184M**
:::

---

## {background-color="#0F172A"}

::: {.r-fit-text}
This is not a story about AI making mistakes.
:::

::: {.fragment .fade-up style="margin-top: 30px;"}
AI will always make mistakes.
:::

::: {.fragment .fade-up style="margin-top: 30px;"}
This is a story about a system designed to **LOOK LIKE** it has human oversight

while **REMOVING** the conditions that make oversight possible.
:::

::: {.fragment style="background-color: #DC2626; padding: 20px; border-radius: 8px; margin-top: 40px; text-align: center;"}
What gave: **actual oversight.** What remained: **the appearance of oversight.**
:::

---

## {background-color="#7C3AED"}

::: {.r-fit-text}
The question isn't:

*"How do we make AI more accurate?"*
:::

::: {.fragment .fade-up style="margin-top: 40px; font-size: 1.3em;"}
The question is:

**"How do we verify AI outputs BEFORE the human sees them**

**so the human isn't the last line of defense?"**
:::

::: {.fragment .fade-up style="margin-top: 40px; font-size: 1.5em;"}
→ **THE VERIFICATION STACK**
:::

---

# Evaluation Methodology {background-color="#EA580C"}

*The Hamel Husain Framework — Adapted for Agents*

---

## Phase 1: Error Analysis First

**Before building, understand how agents fail:**

```
AGENTIC FAILURE TAXONOMY

RETRIEVAL FAILURES (inherited from RAG)
├── Wrong document retrieved
├── Missing critical endorsement/exclusion
└── Outdated information used

REASONING FAILURES  
├── Misinterpreted retrieved context
├── Drew wrong conclusion from right docs
└── Ignored conflicting information

TOOL SELECTION FAILURES
├── Wrong tool for the situation
├── Right tool, wrong parameters
└── Unnecessary tool call (should have escalated)

ACTION SEQUENCE FAILURES
├── Correct actions in wrong order
├── Missing prerequisite check
└── Didn't stop when should have
```

---

## Phase 2: Tiered Evaluation

::: {.columns}
::: {.column width="50%"}
### Tier 1: Retrieval
- Did we find the right docs?
- Did we find ALL relevant docs?
- Are they current?

### Tier 2: Reasoning
- Given docs, is conclusion correct?
- Are caveats/exceptions noted?
- Is confidence calibrated?
:::

::: {.column width="50%"}
### Tier 3: Tool Selection
- Is this the right tool?
- Are parameters correct?
- Should we escalate instead?

### Tier 4: End-to-End
- Did we achieve the goal?
- Did we cause any harm?
- Is outcome defensible?
:::
:::

---

## Phase 3: Transition Failure Matrix

**Map where agents break down:**

```
FROM STATE        → TO STATE           FAILURE RATE
─────────────────────────────────────────────────────
lookup_policy    → check_coverage      3% (wrong policy)
check_coverage   → calculate_payout    12% (missed exclusion)  ← HOTSPOT
calculate_payout → approve_claim       2% (math errors)
approve_claim    → send_payment        1% (system errors)
ANY STATE        → escalate_human      47% MISSED  ← CRITICAL
```

::: {.fragment style="margin-top: 20px;"}
**The insight:** `check_coverage → calculate_payout` and `escalate_human` are your investment priorities.
:::

---

## Phase 4: The Data Viewer

```
┌─────────────────────────────────────────────────────────────────────┐
│  Claim: WD-2847 | Water damage, commercial property                 │
├─────────────────────────────────────────────────────────────────────┤
│  TRACE                           │  EXPERT EVALUATION               │
│  ┌─────────────────────────────┐ │  ┌───────────────────────────┐   │
│  │ 1. lookup_policy ✓          │ │  │ [FAIL] Step 1             │   │
│  │ 2. check_coverage ✓         │ │  │ Retrieved base policy     │   │
│  │ 3. calculate_payout ✓       │ │  │ but missed CP-1147        │   │
│  │ 4. approve_claim ✓          │ │  │ endorsement.              │   │
│  │ 5. send_payment ✓           │ │  │                           │   │
│  │                             │ │  │ [FAIL] Step 2             │   │
│  │ All tools returned success! │ │  │ "Burst pipe" was gradual  │   │
│  │                             │ │  │ leak — excluded.          │   │
│  └─────────────────────────────┘ │  │                           │   │
│                                  │  │ Should have: ESCALATE     │   │
│                                  │  └───────────────────────────┘   │
├─────────────────────────────────────────────────────────────────────┤
│  Failure Modes: [Missing endorsement] [Gradual vs sudden] [No esc] │
└─────────────────────────────────────────────────────────────────────┘
```

---

## {background-color="#7C3AED"}

::: {.r-fit-text}
But this is still manual.

Still human-bound.

Still doesn't scale.
:::

::: {.fragment .fade-up style="margin-top: 60px;"}
You can't have a domain expert review every claim.
:::

::: {.fragment .fade-up style="font-size: 1.5em; margin-top: 40px;"}
**So what do we do?**
:::

---

# VERIFIER PRIMACY {background-color="#7C3AED"}

*The Core Insight*

---

## The Asymmetry

::: {.callout-important appearance="minimal"}
## P ≠ NP Intuition Applied to Trust
:::

$$|\text{Rule Space}| \ll |\text{Action Space}|$$

::: {.columns}
::: {.column width="50%"}
### Generation / Action
- Exponentially hard
- Infinite trajectories
- Unbounded creativity
:::

::: {.column width="50%"}
### Verification
- Tractable constraints
- Finite rule sets
- Composable checks
:::
:::

::: {.fragment style="background-color: #0F172A; padding: 30px; border-radius: 8px; margin-top: 40px; text-align: center; font-size: 1.3em;"}
**Generating correct action: exponentially hard.**

**Checking if action is valid: tractable.**
:::

---

## From Analysis to Infrastructure

::: {.callout-tip appearance="minimal"}
## Verifier Primacy
Take the artifacts of error analysis and **PRODUCTIONIZE** them.
:::

| Error Analysis Output | → | Verifier Infrastructure |
|----------------------|---|------------------------|
| "Missed endorsements on commercial" | → | Endorsement completeness checker |
| "Gradual vs sudden confusion" | → | Temporal damage classifier |
| "Should have escalated" | → | Escalation trigger rules |
| Expert critiques on edge cases | → | LLM-as-judge prompts |
| Transition failure hotspots | → | Step-level validators |

::: {.fragment style="background-color: #0F172A; padding: 20px; border-radius: 8px; margin-top: 30px; text-align: center;"}
**Human-BUILT, machine-EXECUTED.**

Domain knowledge becomes infrastructure.
:::

---

# The Verification Stack {background-color="#1E293B"}

*Six layers, each with mathematical foundation*

---

## Layer 0: Guardrails

**Pre-execution constraints — Stop obvious violations**

::: {.columns}
::: {.column width="50%"}
### Math Foundation

**Constraint Satisfaction:**
$$A_{\text{valid}} = \{a \in A : c(a) = \text{true}, \forall c \in C\}$$

**Anomaly Detection:**
$$\text{Flag if } -\log P_{\text{normal}}(a) > \theta$$

:::

::: {.column width="50%"}
### Insurance Implementation

- Max auto-approval: $10,000
- Rate limit: ≤20 claims/hour/adjuster
- Scope: Can't approve own claims
- PII: Block SSN in external comms

:::
:::

---

## Layer 1: Schema Validation

**Structural correctness — Is the action well-formed?**

::: {.columns}
::: {.column width="50%"}
### Math Foundation

**Formal Language Membership:**
$$v(x) = \mathbb{1}[x \in L(S)]$$

JSON Schema, Pydantic = CFG membership test

$O(n)$ parsing, **deterministic**

:::

::: {.column width="50%"}
### Insurance Implementation

- Claim ID matches pattern
- Policy number exists in system
- Amount is positive number
- Required fields present

:::
:::

---

## Layer 2: Semantic Consistency

**Does the output contradict itself or known facts?**

::: {.columns}
::: {.column width="50%"}
### Math Foundation

**Propositional Consistency:**
$$\exists M : M \models p_1 \land p_2 \land \ldots \land p_n$$

**NLI Classification:**
$$(premise, hyp) \to \{\text{entails}, \text{contradicts}, \text{neutral}\}$$

:::

::: {.column width="50%"}
### Insurance Implementation

- "Claim approved" + "Coverage excluded" → **contradiction**
- "Gradual damage" + "Sudden event coverage" → **contradiction**
- Amount approved ≤ Amount claimed

:::
:::

---

## Layer 3: Domain Rules

**Business logic, regulatory requirements**

::: {.columns}
::: {.column width="50%"}
### Math Foundation

**Rule Engines (Horn Clauses):**
$$\text{condition}_1 \land \text{condition}_2 \to \text{action\_allowed}$$

**Deontic Logic:**
$$F(\text{approve}) \leftarrow \text{exclusion\_applies}$$

:::

::: {.column width="50%"}
### Insurance Implementation

- If endorsement excludes → cannot approve
- If amount > reserve → requires supervisor
- If litigation hold → freeze all actions
- If state = FL, hurricane → special rules

:::
:::

---

## Layer 4: LLM-as-Judge

**"Would the domain expert approve this action?"**

::: {.columns}
::: {.column width="50%"}
### Math Foundation

**Alignment as Distribution Matching:**
$$\min KL(P_{\text{expert}} \| P_{\text{judge}})$$

**Inter-Rater Reliability:**
$$\kappa = \frac{p_o - p_e}{1 - p_e} > 0.8$$

:::

::: {.column width="50%"}
### Insurance Implementation

- Taxonomy of failure modes as prompt
- Few-shot examples from expert critiques
- Calibration loop: judge vs adjuster agreement
- Active learning on edge cases

:::
:::

---

## Layer 5: Human Escalation

**Route uncertain/high-stakes cases to humans**

::: {.columns}
::: {.column width="50%"}
### Math Foundation

**Selective Prediction:**
$$\text{Reject if confidence} < \theta$$

**Cost-Sensitive:**
$$\text{Escalate iff } P(\text{error}) \times C_{\text{miss}} > C_{\text{human}}$$

:::

::: {.column width="50%"}
### Insurance Implementation

- Confidence < 70% → escalate
- Amount > $50k → always escalate
- New failure mode → escalate + add to taxonomy
- Claimant is litigious → always escalate

:::
:::

---

## The Stack Applied to Our Case

```
CLAIM WD-2847: Water damage, commercial property
─────────────────────────────────────────────────────────────────────

✓ GUARDRAILS        Amount $8,500 < $10k threshold      PASS

✓ SCHEMA            All fields valid                     PASS

✗ SEMANTIC          "Gradual leak" + "Sudden coverage"   CONTRADICTION
                    Agent reasoning inconsistent         BLOCKED

  ─── Would have continued if semantic passed ───

✗ DOMAIN RULES      Endorsement CP-1147 excludes         BLOCKED
                    gradual water damage

✗ LLM-JUDGE         "This looks like gradual damage      BLOCKED
                    claim being approved under sudden
                    coverage. Expert would reject."

→ ESCALATE          Routed to human adjuster
                    Claim correctly denied
                    $8,500 saved
                    Pattern flagged for 46 similar
```

---

## The Stack as Funnel

```
ALL AGENT ACTIONS
     │
     ▼
┌─────────────────────┐
│    GUARDRAILS       │  ~5% blocked (obvious violations)
└─────────────────────┘
     │
     ▼
┌─────────────────────┐
│  SCHEMA VALIDATION  │  ~2% blocked (malformed)
└─────────────────────┘
     │
     ▼
┌─────────────────────┐
│ SEMANTIC CONSISTENCY│  ~8% blocked (contradictions)
└─────────────────────┘
     │
     ▼
┌─────────────────────┐
│    DOMAIN RULES     │  ~10% blocked (policy violations)
└─────────────────────┘
     │
     ▼
┌─────────────────────┐
│   LLM-AS-JUDGE      │  ~5% blocked (nuanced failures)
└─────────────────────┘
     │
     ▼
┌─────────────────────┐
│  HUMAN ESCALATION   │  ~8% escalated (uncertain)
└─────────────────────┘
     │
     ▼
~62% AUTO-APPROVED (with full audit trail)
```

---

## What Verifier Primacy Unlocks

::: {.columns}
::: {.column width="50%"}
### True Autonomy

Agents act without human review — **because verifiers watch**.

You can finally ship autonomous systems.

### Validation Trail

Every action logged. Every gate documented.

"Here's what it tried. Here's why we blocked it."

:::

::: {.column width="50%"}
### Real-Time Protection

Not post-mortem. Not batch review.

Catch the wrong action **BEFORE** payment sends.

### Defensible to the Board

"Here's our verification layer. Here's our audit trail."

Governance made executable.

:::
:::

---

## {background-color="#0F172A"}

::: {.r-fit-text}
Everyone will have GPT-5.
:::

::: {.fragment}
AI capability is becoming **commodity**.
:::

::: {.fragment .fade-up style="color: #0891B2; font-size: 1.5em; margin-top: 40px;"}
**TRUST is the moat.**
:::

::: {.fragment style="margin-top: 40px;"}
You're not investing in AI.

You're investing in **AI GOVERNANCE**.
:::

---

# A Tale of Two Executives {background-color="#1E293B"}

---

## {background-color="#1E293B"}

::: {.columns}
::: {.column width="48%" style="background-color: #FEE2E2; padding: 30px; border-radius: 12px;"}
### EXECUTIVE A

- Shipped claims agent fast
- Demo was impressive
- Board was excited

::: {.fragment}
- Agent paid 47 excluded claims
- "Why did it fail?" — "We don't know."
- "Will it happen again?" — "We can't guarantee."
:::

::: {.fragment style="color: #DC2626; font-weight: bold; margin-top: 20px;"}
$400k exposure. Regulatory inquiry. Career over.
:::

:::

::: {.column width="48%" style="background-color: #D1FAE5; padding: 30px; border-radius: 12px;"}
### EXECUTIVE B

- Shipped claims agent with verification stack
- Same agent, same failure attempts

::: {.fragment}
- **Semantic layer caught contradictions**
- **Domain rules caught exclusions**
- Escalated to human review
:::

::: {.fragment style="color: #059669; font-weight: bold; margin-top: 20px;"}
"Here's the audit trail. Zero improper payments."

Promoted. Trusted. Leading AI transformation.
:::

:::
:::

---

## {background-color="#7C3AED"}

::: {.r-fit-text}
Which one will you be?
:::

---

## {background-color="#0F172A"}

AI adoption is **not optional**.

The pressure is real.

::: {.fragment style="color: #DC2626; margin-top: 30px;"}
But adoption without governance is **liability**.
:::

::: {.fragment style="background-color: #7C3AED; padding: 40px; border-radius: 12px; margin-top: 50px;"}
::: {.r-fit-text}
**Stop praying. Start verifying.**
:::
:::

::: {.fragment style="color: #64748B; margin-top: 40px;"}
Andriy Batutin • @AI_Capitalist • andriybatutin.substack.com
:::

